{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9831818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MRoy021\\AppData\\Local\\Temp\\ipykernel_11052\\32513518.py:15: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pat_df= pd.read_csv(obj['Body'])\n",
      "C:\\Users\\MRoy021\\AppData\\Local\\Temp\\ipykernel_11052\\32513518.py:25: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pati_df['month_year'] = pd.to_datetime(pati_df['month_year'])  ## converting month_year column to datetime type\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1047126 entries, 0 to 1047125\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   patient_id  7309 non-null   object \n",
      " 1   month_year  7309 non-null   object \n",
      " 2   Unnamed: 2  0 non-null      float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 24.0+ MB\n",
      "Duplicate values:    0\n",
      "Number of Rows:   3105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MRoy021\\AppData\\Local\\Temp\\ipykernel_11052\\32513518.py:77: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  vt_df= pd.read_csv(obj['Body'])\n",
      "C:\\Users\\MRoy021\\AppData\\Local\\Temp\\ipykernel_11052\\32513518.py:86: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  visit_df.loc[:, 'date'] = pd.to_datetime(visit_df['date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total outpatient_visit_count< 1:    0\n",
      "The number of distinct values of ct_days_with_outpatient_visit:   32\n"
     ]
    }
   ],
   "source": [
    "## Import necessary packages and libraries \n",
    "import boto3\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import numpy as np\n",
    "\n",
    "## *************** Step 1: Data Transformation ****************** ##\n",
    "\n",
    "## Connecting S3 Bucket using Python Boto3 and reading as a dataframe\n",
    "s3 = boto3.resource('s3',\n",
    "         aws_access_key_id= 'AKIAZLXG4RYJBLE4OTXT',\n",
    "         aws_secret_access_key= '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')\n",
    "\n",
    "obj= s3.Bucket('waymark-assignment').Object('patient_id_month_year.csv').get()\n",
    "pat_df= pd.read_csv(obj['Body'])\n",
    "\n",
    "\n",
    "pat_df.info()   ## checking data types\n",
    "\n",
    "pati_df= pat_df.dropna(axis=1, how='all')   ## removing columns with all null values\n",
    "pati_df= pati_df[pati_df['patient_id'].notnull()]  ## remove any null values in patient_id column\n",
    "\n",
    "pati_df = pati_df.reset_index(drop=True)   ## reseting index for easy access\n",
    "\n",
    "pati_df['month_year'] = pd.to_datetime(pati_df['month_year'])  ## converting month_year column to datetime type\n",
    "\n",
    "\n",
    "## sort the dataframe based on patient_id and month_year both in ascensind order so that \n",
    "## for each patient dates are arranged in ascending order\n",
    "pati_df= pati_df.sort_values(by=['patient_id', 'month_year'], ascending=True)   \n",
    "\n",
    "### checking if any duplicate values --> one patient enrolled more than once in a same time period (month and year)\n",
    "pati_df['yr']= pati_df['month_year'].dt.year\n",
    "pati_df['mn']= pati_df['month_year'].dt.month\n",
    "print('Duplicate values:   ', len(pati_df[pati_df.duplicated(['patient_id', 'yr', 'mn'])]))  ## number of duplicates values\n",
    "\n",
    "\n",
    "## Objective: marking all the continuous periods with same number in flag column\n",
    "\n",
    "counter= 0\n",
    "pati_df.at[0, 'flag']= counter   # first flag column value set to 0\n",
    "\n",
    "for i in range(1, len(pati_df)): # loop iterate from 2nd index to the last index and\n",
    "    \n",
    "    # check if current index's patient_id is same to the previous index's patient_id \n",
    "    # adding 1 day to the last day of previous index's month_year is equal to current index's month_year\n",
    "    if ((pd.to_datetime(pati_df.iloc[i-1]['month_year']) + MonthEnd(1)) + pd.DateOffset(1) == pati_df.iloc[i]['month_year']) & (pati_df.iloc[i-1]['patient_id']== pati_df.iloc[i]['patient_id']):\n",
    "        ## continuous period for same patient_id so mark the flag column with the same counter value\n",
    "        pati_df.at[i, 'flag']= counter \n",
    "        \n",
    "    else:\n",
    "        # Not continuous value for same patient_id or different patient_id so mark the falg column with +1 counter value\n",
    "        counter= counter+1\n",
    "        pati_df.at[i, 'flag']= counter\n",
    "\n",
    "## Getting the first and last date for same patiend_id and flag values --> first and last enrollment date for each continuous period for each patient_id\n",
    "pati_df= pati_df.groupby(['patient_id', 'flag'])['month_year'].agg(['first', 'last']).reset_index()\n",
    "\n",
    "pati_df.loc[:, 'enrollment_end_date']= pd.to_datetime(pati_df['last'] + MonthEnd(1)).dt.date # end date of the last enrollment month\n",
    "\n",
    "pati_df= pati_df.rename(columns= {'first': 'enrollment_start_date'})\n",
    "\n",
    "pati_df.drop(columns=['flag', 'last'], inplace= True) # dropping columns\n",
    "pati_df= pati_df.drop_duplicates()  # removing if any duplicate values --> primary key\n",
    "\n",
    "pati_df.to_csv('patient_enrollment_span.csv')  # saving the dataframe as csv file format\n",
    "\n",
    "print('Number of Rows:  ', pati_df.shape[0])  ## printing the number of rows of patient_enrollment_span.csv file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## **********************  Step 2: Data Aggregation  *************************** ##\n",
    "\n",
    "### getting outpatient_visits_file as datafarme\n",
    "obj= s3.Bucket('waymark-assignment').Object('outpatient_visits_file.csv').get()\n",
    "vt_df= pd.read_csv(obj['Body'])\n",
    "\n",
    "visit_df= vt_df.dropna(axis=1, how='all')  ## removing columns with all null values\n",
    "visit_df= visit_df[visit_df['patient_id'].notnull()] ## remove any null values in patient_id column\n",
    "\n",
    "### preprocess patient_id before merging the 2 dataframes\n",
    "visit_df['patient_id']=visit_df['patient_id'].str.rstrip()\n",
    "pati_df['patient_id']=pati_df['patient_id'].str.rstrip()\n",
    "\n",
    "visit_df.loc[:, 'date'] = pd.to_datetime(visit_df['date'])\n",
    "\n",
    "\n",
    "## Inner joining patient enrollemnt period file with outpatient visit file on patient_id \n",
    "pt_vt= pd.merge(pati_df,  visit_df, left_on=['patient_id'], right_on= ['patient_id'])\n",
    "\n",
    "pt_vt['enrollment_end_date'] = pd.to_datetime(pt_vt['enrollment_end_date'])\n",
    "\n",
    "## considering only those rows which have outpatient visit dates between enrollment start and end date inclusive\n",
    "pt_vt['flag']= 'N'   ## marking all rows as N\n",
    "pt_vt.loc[(pt_vt['date']>= pt_vt['enrollment_start_date']) & (pt_vt['date']<= pt_vt['enrollment_end_date']), 'flag']= 'Y'  ## if in between mark Y\n",
    "pt_vt= pt_vt[pt_vt['flag']=='Y']  ## consider only in between rows\n",
    "\n",
    "## if any outpatient_visit_count<1\n",
    "print('Total outpatient_visit_count< 1:   ', len(pt_vt[pt_vt['outpatient_visit_count']<1]))  \n",
    "\n",
    "## For each unique patient_id, enrollment_start_date and enrollment_end_date combination \n",
    "## find ct_outpatient_visits by summing all outpatient_visit_count\n",
    "## find the number of distinct days visit within an enrollment period by the unique date count\n",
    "result= pt_vt.groupby(['patient_id', 'enrollment_start_date', 'enrollment_end_date']).agg({'outpatient_visit_count':'sum', 'date':'nunique'}).reset_index()\n",
    "\n",
    "result= result.rename(columns= {'outpatient_visit_count': 'ct_outpatient_visits', 'date': 'ct_days_with_outpatient_visit'})\n",
    "\n",
    "result.to_csv('result.csv')  ## saving the result dataframe in csv file format\n",
    "\n",
    "print('The number of distinct values of ct_days_with_outpatient_visit:  ', result['ct_days_with_outpatient_visit'].nunique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
